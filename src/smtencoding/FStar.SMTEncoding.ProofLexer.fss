{

module FStar.SMTEncoding.ProofLexer

open Microsoft.FSharp.Text.Lexing
open System
open System.Numerics
open FStar.SMTEncoding.ProofParser

let keywords =
    [ "!", ANNOTATION;
      "_", PARAMETRIC;
      "not", NOT;
      "and", AND;
      "or", OR;
      "=>", IMPLIES;
      "=", EQUAL;
      "~", EQUIV;
      "<=", LEQ;
      "<", LT;
      ">=", GEQ;
      ">", GT;
      "+", PLUS;
      "*", TIMES;
      "-", MINUS;
      "forall", FORALL;
      "lambda", LAMBDA;
      "let", LET;
      "true", TRUE;
      "false", FALSE;
      ":pattern", PATTERN;
      ":qid", QID;
      "proof", PROOF;
      "declare-fun", FUNCTION;
      "Term", TERM;
      "Bool", BOOLEAN;
      "FString", STRING;
      "Int", INTEGER;
      "Fuel", FUEL;
      "quant-intro", ARBITRARY;
      "monotonicity", CONGRUENCE;
      "refl", REFLEXIVITY;
      "symm", SYMMETRY;
      "trans", TRANSITIVITY;
      "trans*", REACHABILITY;
      "proof-bind", GENERALIZATION;
      "nnf-pos", POSITIVE_NNF;
      "nnf-neg", NEGATIVE_NNF;
      "rewrite", REWRITING;
      "mp", MODUS_PONENS;
      "mp~", MODUS_PONENS_EQUIV;
      "unit-resolution", UNIT_RESOLUTION;
      "asserted", AXIOM;
      "th-lemma", THEORY_LEMMA;
      "quant-inst", INSTANTIATION;
      "sk" , SKOLEMIZATION;
      "arith", ARITHMETICS;
      "triangle-eq" , TRIANGLE_INEQUALITY;
      "farkas", FARKAS_LEMMA ] |> Map.ofList

let lexeme (lexbuf : LexBuffer<char>) = new System.String(lexbuf.Lexeme)

}

let digit = ['0'-'9']
let int = '-'?digit+
let char = ['a'-'z' 'A'-'Z' '@' '|' '%' '_' '.' '>' '=' '<' '!' '$' '#' '+' '-' '*' '\'' '/']
let weird = [':']
let ident = char(char|digit|weird)*
let symbol = ':'ident
let whitespace = [' ' '\t']
let comment = ';'[^'\n' '\r']*
let newline = ('\n' | '\r' '\n')

rule tokenize = parse
| newline { lexbuf.EndPos <- lexbuf.EndPos.NextLine; tokenize lexbuf }
| whitespace { tokenize lexbuf }
| comment { tokenize lexbuf }
| int { INT(BigInteger.Parse(lexeme lexbuf)) }
| symbol { match keywords.TryFind(lexeme lexbuf) with   
               | Some(token) -> token   
               | None -> ID(lexeme lexbuf)
               }
| '(' { LPAREN }
| ')' { RPAREN }
| ident { match keywords.TryFind(lexeme lexbuf) with   
               | Some(token) -> token   
               | None -> ID(lexeme lexbuf)
               }
| eof { EOF }